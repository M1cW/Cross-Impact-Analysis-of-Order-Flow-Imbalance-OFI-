{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Notebook for the task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 Compute OFI metrics \n",
    "1. Derive multi-level OFI metrics (up to 5 levels) for each stock in the dataset.\n",
    "2. Integrate these multi-level OFIs into a single metric using Principal Component Analysis (PCA) or another dimensionality reduction method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data-preprocessing\n",
    "I followed the instructions and retrieved data from AAPL, AMGN, TSLA, JPM, XOM from period 12/07/2024 to 01/07/2025 (one month).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import databento as db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/mic/Desktop/Github/Cross-Impact-Analysis-of-Order-Flow-Imbalance-OFI-/data/XNAS-20250107-APPL',\n",
       " '/Users/mic/Desktop/Github/Cross-Impact-Analysis-of-Order-Flow-Imbalance-OFI-/data/XNAS-20250107-AMGN',\n",
       " '/Users/mic/Desktop/Github/Cross-Impact-Analysis-of-Order-Flow-Imbalance-OFI-/data/XNAS-20250107-TSLA',\n",
       " '/Users/mic/Desktop/Github/Cross-Impact-Analysis-of-Order-Flow-Imbalance-OFI-/data/XNAS-20250107-JPM',\n",
       " '/Users/mic/Desktop/Github/Cross-Impact-Analysis-of-Order-Flow-Imbalance-OFI-/data/XNAS-20250107-XOM']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_directory=[]\n",
    "\n",
    "data_directory_AAPL=f\"/Users/mic/Desktop/Github/Cross-Impact-Analysis-of-Order-Flow-Imbalance-OFI-/data/XNAS-20250107-APPL\"\n",
    "data_directory_AMGN=f\"/Users/mic/Desktop/Github/Cross-Impact-Analysis-of-Order-Flow-Imbalance-OFI-/data/XNAS-20250107-AMGN\"\n",
    "data_directory_TSLA=f\"/Users/mic/Desktop/Github/Cross-Impact-Analysis-of-Order-Flow-Imbalance-OFI-/data/XNAS-20250107-TSLA\"\n",
    "data_directory_JPM=f\"/Users/mic/Desktop/Github/Cross-Impact-Analysis-of-Order-Flow-Imbalance-OFI-/data/XNAS-20250107-JPM\"\n",
    "data_directory_XOM=f\"/Users/mic/Desktop/Github/Cross-Impact-Analysis-of-Order-Flow-Imbalance-OFI-/data/XNAS-20250107-XOM\"\n",
    "\n",
    "data_directory.append(data_directory_AAPL)\n",
    "data_directory.append(data_directory_AMGN)\n",
    "data_directory.append(data_directory_TSLA)\n",
    "data_directory.append(data_directory_JPM)\n",
    "data_directory.append(data_directory_XOM)\n",
    "\n",
    "data_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making the downloads into dataframe. There are .dbn.zst files for days of MBP-10 order books, we transform it into pandas dataframe and concatenate data for days into a big dataset for each of the five companies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_dataframes=[]\n",
    "dataframes=[]\n",
    "for data_directory_company in data_directory:\n",
    "    for filename in os.listdir(data_directory_company):\n",
    "        if filename.endswith(\".dbn.zst\"):\n",
    "            file_path=os.path.join(data_directory_company, filename)\n",
    "            file_df=db.DBNStore.from_file(file_path).to_df()\n",
    "            dataframes.append(file_df)\n",
    "    combined_dataframes.append(pd.concat(dataframes, ignore_index=True))\n",
    "    dataframes=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined_dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df_AAPL=combined_dataframes[0]\n",
    "combined_df_AMGN=combined_dataframes[1]\n",
    "combined_df_TSLA=combined_dataframes[2]\n",
    "combined_df_JPM=combined_dataframes[3]\n",
    "combined_df_XOM=combined_dataframes[4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25602477, 78)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df_AAPL.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'combined_df_AAPL' (DataFrame)\n",
      "Stored 'combined_df_AMGN' (DataFrame)\n",
      "Stored 'combined_df_TSLA' (DataFrame)\n",
      "Stored 'combined_df_JPM' (DataFrame)\n",
      "Stored 'combined_df_XOM' (DataFrame)\n"
     ]
    }
   ],
   "source": [
    "%store combined_df_AAPL\n",
    "%store combined_df_AMGN\n",
    "%store combined_df_TSLA\n",
    "%store combined_df_JPM\n",
    "%store combined_df_XOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ts_event', 'rtype', 'publisher_id', 'instrument_id', 'action', 'side',\n",
       "       'depth', 'price', 'size', 'flags', 'ts_in_delta', 'sequence',\n",
       "       'bid_px_00', 'ask_px_00', 'bid_sz_00', 'ask_sz_00', 'bid_ct_00',\n",
       "       'ask_ct_00', 'bid_px_01', 'ask_px_01', 'bid_sz_01', 'ask_sz_01',\n",
       "       'bid_ct_01', 'ask_ct_01', 'bid_px_02', 'ask_px_02', 'bid_sz_02',\n",
       "       'ask_sz_02', 'bid_ct_02', 'ask_ct_02', 'bid_px_03', 'ask_px_03',\n",
       "       'bid_sz_03', 'ask_sz_03', 'bid_ct_03', 'ask_ct_03', 'bid_px_04',\n",
       "       'ask_px_04', 'bid_sz_04', 'ask_sz_04', 'bid_ct_04', 'ask_ct_04',\n",
       "       'bid_px_05', 'ask_px_05', 'bid_sz_05', 'ask_sz_05', 'bid_ct_05',\n",
       "       'ask_ct_05', 'bid_px_06', 'ask_px_06', 'bid_sz_06', 'ask_sz_06',\n",
       "       'bid_ct_06', 'ask_ct_06', 'bid_px_07', 'ask_px_07', 'bid_sz_07',\n",
       "       'ask_sz_07', 'bid_ct_07', 'ask_ct_07', 'bid_px_08', 'ask_px_08',\n",
       "       'bid_sz_08', 'ask_sz_08', 'bid_ct_08', 'ask_ct_08', 'bid_px_09',\n",
       "       'ask_px_09', 'bid_sz_09', 'ask_sz_09', 'bid_ct_09', 'ask_ct_09',\n",
       "       'symbol'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df_AAPL.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the columns bid_px_N denote the bid price at level N (top level then N=00), bid_sz_N denote the bid size at level N. Similarily for ask levels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implement the best level OFI algorithm as described in the paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_best_level_ofi(df):\n",
    "    \"\"\"\n",
    "    Compute best-level OFI (Order Flow Imbalance)\n",
    "    We assume df has columns:\n",
    "      'bid_px_01', 'bid_sz_01',\n",
    "      'ask_px_01', 'ask_sz_01'\n",
    "    \n",
    "    Algorithm based on the paper\n",
    "    \"\"\"\n",
    "    # First, shift columns to compare current row with previous\n",
    "    df['prev_bid_px'] = df['bid_px_01'].shift()\n",
    "    df['prev_bid_sz'] = df['bid_sz_01'].shift()\n",
    "    df['prev_ask_px'] = df['ask_px_01'].shift()\n",
    "    df['prev_ask_sz'] = df['ask_sz_01'].shift()\n",
    "\n",
    "    # 1) BID-SIDE OFI\n",
    "    # Masks for NaN (the first row), up, down, same\n",
    "    mask_bid_nan  = df['prev_bid_px'].isna()\n",
    "    mask_bid_up   = df['bid_px_01']  > df['prev_bid_px']\n",
    "    mask_bid_down = df['bid_px_01']  < df['prev_bid_px']\n",
    "    mask_bid_same = ~(mask_bid_up | mask_bid_down | mask_bid_nan)\n",
    "    \n",
    "    # Use np.select to assign the correct value for each row\n",
    "    of_bid = np.select(\n",
    "        [mask_bid_nan, mask_bid_up, mask_bid_down, mask_bid_same],\n",
    "        [0.0, df['bid_sz_01'], -df['bid_sz_01'], df['bid_sz_01'] - df['prev_bid_sz']],\n",
    "        default=0.0\n",
    "    )\n",
    "\n",
    "    # 2) ASK-SIDE OFI\n",
    "    # Similarily\n",
    "    mask_ask_nan  = df['prev_ask_px'].isna()\n",
    "    mask_ask_down = df['ask_px_01']  < df['prev_ask_px']\n",
    "    mask_ask_up   = df['ask_px_01']  > df['prev_ask_px']\n",
    "    mask_ask_same = ~(mask_ask_down | mask_ask_up | mask_ask_nan)\n",
    "    \n",
    "    of_ask = np.select(\n",
    "        [mask_ask_nan, mask_ask_down, mask_ask_up, mask_ask_same],\n",
    "        [0.0, df['ask_sz_01'], -df['ask_sz_01'], df['ask_sz_01'] - df['prev_ask_sz']],\n",
    "        default=0.0\n",
    "    )\n",
    "    \n",
    "    # ---------------------------\n",
    "    # 3) Combine to get best-level OFI\n",
    "    # ---------------------------\n",
    "    df['best_level_ofi'] = of_bid - of_ask\n",
    "    return df['best_level_ofi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_level_ofi_AAPL = compute_best_level_ofi_vectorized(combined_df_AAPL)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25602477,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_level_ofi_AAPL.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_level_ofi_AMGN = compute_best_level_ofi(combined_df_AMGN)\n",
    "best_level_ofi_TSLA = compute_best_level_ofi(combined_df_TSLA)\n",
    "best_level_ofi_JPM = compute_best_level_ofi(combined_df_JPM)\n",
    "best_level_ofi_XOM = compute_best_level_ofi(combined_df_XOM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1550548,)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_level_ofi_AMGN.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_multi_level_ofi(df, levels=range(2,6)):\n",
    "    \"\"\"\n",
    "     multi-level OFI computation for levels 2..5 \n",
    "\n",
    "    Returns a DataFrame of only the multi-level OFI columns:\n",
    "        ofi_lvl_2, ofi_lvl_3, ofi_lvl_4, ofi_lvl_5\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    ofi_results = {}\n",
    "\n",
    "    for lvl in levels:\n",
    "        px_bid_col = f'bid_px_0{lvl}'\n",
    "        sz_bid_col = f'bid_sz_0{lvl}'\n",
    "        px_ask_col = f'ask_px_0{lvl}'\n",
    "        sz_ask_col = f'ask_sz_0{lvl}'\n",
    "\n",
    "        # Shift columns to compare to previous row\n",
    "        df[f'prev_bid_px_{lvl}'] = df[px_bid_col].shift()\n",
    "        df[f'prev_bid_sz_{lvl}'] = df[sz_bid_col].shift()\n",
    "        df[f'prev_ask_px_{lvl}'] = df[px_ask_col].shift()\n",
    "        df[f'prev_ask_sz_{lvl}'] = df[sz_ask_col].shift()\n",
    "\n",
    "        # Bid side\n",
    "        mask_bid_nan  = df[f'prev_bid_px_{lvl}'].isna()  # first row or missing\n",
    "        mask_bid_up   = df[px_bid_col] > df[f'prev_bid_px_{lvl}']\n",
    "        mask_bid_down = df[px_bid_col] < df[f'prev_bid_px_{lvl}']\n",
    "        mask_bid_same = ~(mask_bid_nan | mask_bid_up | mask_bid_down)\n",
    "\n",
    "        of_bid = np.select(\n",
    "            [mask_bid_nan, mask_bid_up, mask_bid_down, mask_bid_same],\n",
    "            [0.0, df[sz_bid_col], -df[sz_bid_col], df[sz_bid_col] - df[f'prev_bid_sz_{lvl}']],\n",
    "            default=0.0\n",
    "        )\n",
    "\n",
    "        # Ask side\n",
    "        mask_ask_nan  = df[f'prev_ask_px_{lvl}'].isna()\n",
    "        mask_ask_down = df[px_ask_col] < df[f'prev_ask_px_{lvl}']\n",
    "        mask_ask_up   = df[px_ask_col] > df[f'prev_ask_px_{lvl}']\n",
    "        mask_ask_same = ~(mask_ask_nan | mask_ask_down | mask_ask_up)\n",
    "\n",
    "        of_ask = np.select(\n",
    "            [mask_ask_nan, mask_ask_down, mask_ask_up, mask_ask_same],\n",
    "            [0.0, df[sz_ask_col], -df[sz_ask_col], df[sz_ask_col] - df[f'prev_ask_sz_{lvl}']],\n",
    "            default=0.0\n",
    "        )\n",
    "\n",
    "        # ---------------------------\n",
    "        # Combine to get OFI at this level\n",
    "        # ---------------------------\n",
    "        ofi_lvl = of_bid - of_ask\n",
    "        ofi_results[f'ofi_lvl_{lvl}'] = ofi_lvl\n",
    "\n",
    "    # Append the results to the DataFrame\n",
    "    for col_name, col_array in ofi_results.items():\n",
    "        df[col_name] = col_array\n",
    "\n",
    "    # Return only the columns of interest (the multi-level OFI columns)\n",
    "    ofi_cols = list(ofi_results.keys())\n",
    "    return df[ofi_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m multi_level_ofi_AAPL \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_multi_level_ofi_vectorized\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombined_df_AAPL\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m multi_level_ofi_AAPL\u001b[38;5;241m.\u001b[39mhead()\n",
      "Cell \u001b[0;32mIn [21], line 23\u001b[0m, in \u001b[0;36mcompute_multi_level_ofi_vectorized\u001b[0;34m(df, levels)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mVectorized multi-level OFI computation for levels 2..5 (or any iterable `levels`).\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;124;03m(or whatever levels are requested).\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Make a copy to avoid side effects (optional)\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# Dictionary to hold the final OFI arrays (one per level)\u001b[39;00m\n\u001b[1;32m     26\u001b[0m ofi_results \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/generic.py:6811\u001b[0m, in \u001b[0;36mNDFrame.copy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m   6662\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[1;32m   6663\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcopy\u001b[39m(\u001b[38;5;28mself\u001b[39m, deep: bool_t \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m   6664\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   6665\u001b[0m \u001b[38;5;124;03m    Make a copy of this object's indices and data.\u001b[39;00m\n\u001b[1;32m   6666\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6809\u001b[0m \u001b[38;5;124;03m    dtype: int64\u001b[39;00m\n\u001b[1;32m   6810\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 6811\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6812\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clear_item_cache()\n\u001b[1;32m   6813\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(data, axes\u001b[38;5;241m=\u001b[39mdata\u001b[38;5;241m.\u001b[39maxes)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[1;32m   6814\u001b[0m         \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcopy\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   6815\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/internals/managers.py:593\u001b[0m, in \u001b[0;36mBaseBlockManager.copy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    590\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    591\u001b[0m         new_axes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n\u001b[0;32m--> 593\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcopy\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    594\u001b[0m res\u001b[38;5;241m.\u001b[39maxes \u001b[38;5;241m=\u001b[39m new_axes\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    597\u001b[0m     \u001b[38;5;66;03m# Avoid needing to re-compute these\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/internals/managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/core/internals/blocks.py:796\u001b[0m, in \u001b[0;36mBlock.copy\u001b[0;34m(self, deep)\u001b[0m\n\u001b[1;32m    794\u001b[0m refs: BlockValuesRefs \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    795\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[0;32m--> 796\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43mvalues\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    797\u001b[0m     refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    798\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "multi_level_ofi_AAPL = compute_multi_level_ofi(combined_df_AAPL)\n",
    "multi_level_ofi_AAPL.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25602477, 4)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_level_ofi_AAPL.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the OFI level 1-5 for each 5 stocks, we can then perform PCA and look for the dominant pinciple component and use it to calculate the \"\"Integrated OFI\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
